{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b4d7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e653f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    return int(filename.split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a90c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5390a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LITBANK_INDEX=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df7b1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_folder_path = '../data/NewLitBank_v2/NewLitBank_v2'\n",
    "litbank_file_list = sorted(os.listdir(check_folder_path), key=extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "161a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = pd.read_csv(check_folder_path + '/' + litbank_file_list[LITBANK_INDEX], index_col=0)\n",
    "df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "df_case['inference_offsets'] = [ast.literal_eval(data) for data in df_case['inference_offsets']]\n",
    "df_case = df_case[df_case['update_text'].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dh = pd.read_csv(PATH + '/NewLitBank_dh/' + litbank_file_list[LITBANK_INDEX], index_col=0)\n",
    "df_js = pd.read_csv(PATH + '/NewLitBank_JS/' + litbank_file_list[LITBANK_INDEX], index_col=0).reset_index(drop=True)\n",
    "df_gy = pd.read_csv(PATH + '/NewLitBank_gy/' + litbank_file_list[LITBANK_INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db318ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref</th>\n",
       "      <th>extracted_sentence</th>\n",
       "      <th>adjusted_offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>inference_offsets</th>\n",
       "      <th>labels</th>\n",
       "      <th>update_text</th>\n",
       "      <th>update_sentence</th>\n",
       "      <th>update_coref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[450, 454], [18, 19], [22, 23], [247, 250], [...</td>\n",
       "      <td>[To, accommodate, the, regiments, of, miners, ...</td>\n",
       "      <td>[[35, 39], [64, 65], [68, 69], [90, 93], [116,...</td>\n",
       "      <td>[[the, site, of, Hell, Row], [Hell, Row], [Hel...</td>\n",
       "      <td>[[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['the', 'site', 'of', 'Hell', 'Row'], ['notor...</td>\n",
       "      <td>['To', 'accommodate', 'the', 'regiments', 'of'...</td>\n",
       "      <td>[[35, 39], [64, 66], [69, 71], [92, 95], [118,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[43, 53], [605, 606], [144, 145]]</td>\n",
       "      <td>[There, lived, the, colliers, who, worked, in,...</td>\n",
       "      <td>[[2, 12], [30, 31], [39, 40]]</td>\n",
       "      <td>[[the, colliers, who, worked, in, the, little,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['the', 'colliers', 'who', 'worked', 'in', 't...</td>\n",
       "      <td>['There', 'lived', 'the', 'colliers', 'who', '...</td>\n",
       "      <td>[[2, 12], [30, 32], [40, 42]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[209, 209], [393, 393]]</td>\n",
       "      <td>[The, coal, and, iron, field, of, Nottinghamsh...</td>\n",
       "      <td>[[8, 8], [92, 92]]</td>\n",
       "      <td>[[Derbyshire], [Derbyshire]]</td>\n",
       "      <td>[[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Derbyshire'], ['picturesque', 'Derbyshire']]</td>\n",
       "      <td>['The', 'coal', 'and', 'iron', 'field', 'of', ...</td>\n",
       "      <td>[[8, 8], [92, 93]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[345, 346], [234, 235]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[32, 33], [116, 117]]</td>\n",
       "      <td>[[Spinney, Park], [Spinney, Park]]</td>\n",
       "      <td>[[[39, 39], [48, 48]], [[56, 58], [62, 62]]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Spinney', 'picturesque', 'Park'], ['Spinney...</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[32, 34], [117, 119]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[382, 382], [296, 296]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[69, 69], [125, 125]]</td>\n",
       "      <td>[[Selby], [Selby]]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Selby'], ['the', 'nearby', 'Selby']]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[69, 69], [125, 127]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[314, 314], [298, 298]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[1, 1], [127, 127]]</td>\n",
       "      <td>[[Nuttall], [Nuttall]]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Nuttall'], ['Nuttall', 'new']]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[1, 1], [127, 128]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[1162, 1162], [1183, 1183]]</td>\n",
       "      <td>[“, They, 'll, be, beginnin, ', ,, ”, the, boy...</td>\n",
       "      <td>[[1, 1], [22, 22]]</td>\n",
       "      <td>[[They], [they]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['They'], ['the', 'mother']]</td>\n",
       "      <td>['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...</td>\n",
       "      <td>[[1, 1], [22, 23]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               coref  \\\n",
       "0  [[450, 454], [18, 19], [22, 23], [247, 250], [...   \n",
       "1                 [[43, 53], [605, 606], [144, 145]]   \n",
       "2                           [[209, 209], [393, 393]]   \n",
       "3                           [[345, 346], [234, 235]]   \n",
       "4                           [[382, 382], [296, 296]]   \n",
       "5                           [[314, 314], [298, 298]]   \n",
       "6                       [[1162, 1162], [1183, 1183]]   \n",
       "\n",
       "                                  extracted_sentence  \\\n",
       "0  [To, accommodate, the, regiments, of, miners, ...   \n",
       "1  [There, lived, the, colliers, who, worked, in,...   \n",
       "2  [The, coal, and, iron, field, of, Nottinghamsh...   \n",
       "3  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "4  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "5  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "6  [“, They, 'll, be, beginnin, ', ,, ”, the, boy...   \n",
       "\n",
       "                                    adjusted_offsets  \\\n",
       "0  [[35, 39], [64, 65], [68, 69], [90, 93], [116,...   \n",
       "1                      [[2, 12], [30, 31], [39, 40]]   \n",
       "2                                 [[8, 8], [92, 92]]   \n",
       "3                             [[32, 33], [116, 117]]   \n",
       "4                             [[69, 69], [125, 125]]   \n",
       "5                               [[1, 1], [127, 127]]   \n",
       "6                                 [[1, 1], [22, 22]]   \n",
       "\n",
       "                                                text  \\\n",
       "0  [[the, site, of, Hell, Row], [Hell, Row], [Hel...   \n",
       "1  [[the, colliers, who, worked, in, the, little,...   \n",
       "2                       [[Derbyshire], [Derbyshire]]   \n",
       "3                 [[Spinney, Park], [Spinney, Park]]   \n",
       "4                                 [[Selby], [Selby]]   \n",
       "5                             [[Nuttall], [Nuttall]]   \n",
       "6                                   [[They], [they]]   \n",
       "\n",
       "                                   inference_offsets  labels  \\\n",
       "0  [[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...       0   \n",
       "1                                                 []       0   \n",
       "2  [[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...       0   \n",
       "3       [[[39, 39], [48, 48]], [[56, 58], [62, 62]]]       0   \n",
       "4  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "5  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "6                                                 []       0   \n",
       "\n",
       "                                         update_text  \\\n",
       "0  [['the', 'site', 'of', 'Hell', 'Row'], ['notor...   \n",
       "1  [['the', 'colliers', 'who', 'worked', 'in', 't...   \n",
       "2    [['Derbyshire'], ['picturesque', 'Derbyshire']]   \n",
       "3  [['Spinney', 'picturesque', 'Park'], ['Spinney...   \n",
       "4            [['Selby'], ['the', 'nearby', 'Selby']]   \n",
       "5                  [['Nuttall'], ['Nuttall', 'new']]   \n",
       "6                      [['They'], ['the', 'mother']]   \n",
       "\n",
       "                                     update_sentence  \\\n",
       "0  ['To', 'accommodate', 'the', 'regiments', 'of'...   \n",
       "1  ['There', 'lived', 'the', 'colliers', 'who', '...   \n",
       "2  ['The', 'coal', 'and', 'iron', 'field', 'of', ...   \n",
       "3  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "4  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "5  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "6  ['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...   \n",
       "\n",
       "                                        update_coref  \n",
       "0  [[35, 39], [64, 66], [69, 71], [92, 95], [118,...  \n",
       "1                      [[2, 12], [30, 32], [40, 42]]  \n",
       "2                                 [[8, 8], [92, 93]]  \n",
       "3                             [[32, 34], [117, 119]]  \n",
       "4                             [[69, 69], [125, 127]]  \n",
       "5                               [[1, 1], [127, 128]]  \n",
       "6                                 [[1, 1], [22, 23]]  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58ba324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref</th>\n",
       "      <th>extracted_sentence</th>\n",
       "      <th>adjusted_offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>inference_offsets</th>\n",
       "      <th>labels</th>\n",
       "      <th>update_text</th>\n",
       "      <th>update_sentence</th>\n",
       "      <th>update_coref</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[450, 454], [18, 19], [22, 23], [247, 250], [...</td>\n",
       "      <td>['To', 'accommodate', 'the', 'regiments', 'of'...</td>\n",
       "      <td>[[35, 39], [64, 65], [68, 69], [90, 93], [116,...</td>\n",
       "      <td>[['the', 'site', 'of', 'Hell', 'Row'], ['Hell'...</td>\n",
       "      <td>[[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['the', 'site', 'of', 'Hell', 'Row'], ['notor...</td>\n",
       "      <td>['To', 'accommodate', 'the', 'regiments', 'of'...</td>\n",
       "      <td>[[35, 39], [64, 66], [69, 71], [92, 95], [118,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[43, 53], [605, 606], [144, 145]]</td>\n",
       "      <td>['There', 'lived', 'the', 'colliers', 'who', '...</td>\n",
       "      <td>[[2, 12], [30, 31], [39, 40]]</td>\n",
       "      <td>[['the', 'colliers', 'who', 'worked', 'in', 't...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['the', 'colliers', 'who', 'worked', 'in', 't...</td>\n",
       "      <td>['There', 'lived', 'the', 'colliers', 'who', '...</td>\n",
       "      <td>[[2, 12], [30, 32], [40, 42]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[209, 209], [393, 393]]</td>\n",
       "      <td>['The', 'coal', 'and', 'iron', 'field', 'of', ...</td>\n",
       "      <td>[[8, 8], [92, 92]]</td>\n",
       "      <td>[['Derbyshire'], ['Derbyshire']]</td>\n",
       "      <td>[[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Derbyshire'], ['picturesque', 'Derbyshire']]</td>\n",
       "      <td>['The', 'coal', 'and', 'iron', 'field', 'of', ...</td>\n",
       "      <td>[[8, 8], [92, 93]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[345, 346], [234, 235]]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[32, 33], [116, 117]]</td>\n",
       "      <td>[['Spinney', 'Park'], ['Spinney', 'Park']]</td>\n",
       "      <td>[[[39, 39], [48, 48]], [[56, 58], [62, 62]]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Spinney', 'picturesque', 'Park'], ['Spinney...</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[32, 34], [117, 119]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[382, 382], [296, 296]]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[69, 69], [125, 125]]</td>\n",
       "      <td>[['Selby'], ['Selby']]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Selby'], ['the', 'nearby', 'Selby']]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[69, 69], [125, 127]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[314, 314], [298, 298]]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[1, 1], [127, 127]]</td>\n",
       "      <td>[['Nuttall'], ['Nuttall']]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[['Nuttall'], ['Nuttall', 'new']]</td>\n",
       "      <td>['From', 'Nuttall', ',', 'high', 'up', 'on', '...</td>\n",
       "      <td>[[1, 1], [127, 128]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[1162, 1162], [1183, 1183]]</td>\n",
       "      <td>['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...</td>\n",
       "      <td>[[1, 1], [22, 22]]</td>\n",
       "      <td>[['They'], ['they']]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[['They'], ['the', 'mother']]</td>\n",
       "      <td>['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...</td>\n",
       "      <td>[[1, 1], [22, 23]]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               coref  \\\n",
       "0  [[450, 454], [18, 19], [22, 23], [247, 250], [...   \n",
       "1                 [[43, 53], [605, 606], [144, 145]]   \n",
       "2                           [[209, 209], [393, 393]]   \n",
       "3                           [[345, 346], [234, 235]]   \n",
       "4                           [[382, 382], [296, 296]]   \n",
       "5                           [[314, 314], [298, 298]]   \n",
       "6                       [[1162, 1162], [1183, 1183]]   \n",
       "\n",
       "                                  extracted_sentence  \\\n",
       "0  ['To', 'accommodate', 'the', 'regiments', 'of'...   \n",
       "1  ['There', 'lived', 'the', 'colliers', 'who', '...   \n",
       "2  ['The', 'coal', 'and', 'iron', 'field', 'of', ...   \n",
       "3  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "4  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "5  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "6  ['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...   \n",
       "\n",
       "                                    adjusted_offsets  \\\n",
       "0  [[35, 39], [64, 65], [68, 69], [90, 93], [116,...   \n",
       "1                      [[2, 12], [30, 31], [39, 40]]   \n",
       "2                                 [[8, 8], [92, 92]]   \n",
       "3                             [[32, 33], [116, 117]]   \n",
       "4                             [[69, 69], [125, 125]]   \n",
       "5                               [[1, 1], [127, 127]]   \n",
       "6                                 [[1, 1], [22, 22]]   \n",
       "\n",
       "                                                text  \\\n",
       "0  [['the', 'site', 'of', 'Hell', 'Row'], ['Hell'...   \n",
       "1  [['the', 'colliers', 'who', 'worked', 'in', 't...   \n",
       "2                   [['Derbyshire'], ['Derbyshire']]   \n",
       "3         [['Spinney', 'Park'], ['Spinney', 'Park']]   \n",
       "4                             [['Selby'], ['Selby']]   \n",
       "5                         [['Nuttall'], ['Nuttall']]   \n",
       "6                               [['They'], ['they']]   \n",
       "\n",
       "                                   inference_offsets  labels  \\\n",
       "0  [[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...       0   \n",
       "1                                                 []       0   \n",
       "2  [[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...       0   \n",
       "3       [[[39, 39], [48, 48]], [[56, 58], [62, 62]]]       0   \n",
       "4  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "5  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "6                                                 []       0   \n",
       "\n",
       "                                         update_text  \\\n",
       "0  [['the', 'site', 'of', 'Hell', 'Row'], ['notor...   \n",
       "1  [['the', 'colliers', 'who', 'worked', 'in', 't...   \n",
       "2    [['Derbyshire'], ['picturesque', 'Derbyshire']]   \n",
       "3  [['Spinney', 'picturesque', 'Park'], ['Spinney...   \n",
       "4            [['Selby'], ['the', 'nearby', 'Selby']]   \n",
       "5                  [['Nuttall'], ['Nuttall', 'new']]   \n",
       "6                      [['They'], ['the', 'mother']]   \n",
       "\n",
       "                                     update_sentence  \\\n",
       "0  ['To', 'accommodate', 'the', 'regiments', 'of'...   \n",
       "1  ['There', 'lived', 'the', 'colliers', 'who', '...   \n",
       "2  ['The', 'coal', 'and', 'iron', 'field', 'of', ...   \n",
       "3  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "4  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "5  ['From', 'Nuttall', ',', 'high', 'up', 'on', '...   \n",
       "6  ['“', 'They', \"'ll\", 'be', 'beginnin', \"'\", ',...   \n",
       "\n",
       "                                        update_coref  cases  \n",
       "0  [[35, 39], [64, 66], [69, 71], [92, 95], [118,...      0  \n",
       "1                      [[2, 12], [30, 32], [40, 42]]      0  \n",
       "2                                 [[8, 8], [92, 93]]      0  \n",
       "3                             [[32, 34], [117, 119]]      1  \n",
       "4                             [[69, 69], [125, 127]]      0  \n",
       "5                               [[1, 1], [127, 128]]      1  \n",
       "6                                 [[1, 1], [22, 23]]      2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f1eed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d3c9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_labels(count_matrix):\n",
    "    argmax_labels = []\n",
    "    for row in count_matrix:\n",
    "        # 가장 큰 값의 인덱스들 (tie 가능성 고려)\n",
    "        max_val = np.max(row)\n",
    "        max_indices = np.where(row == max_val)[0]\n",
    "\n",
    "        if len(max_indices) == 1:\n",
    "            argmax_labels.append(max_indices[0])  # 유일한 최댓값이면 그 index\n",
    "        else:\n",
    "            argmax_labels.append(1)\n",
    "    return argmax_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ff158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:01<00:00, 66.47it/s]\n"
     ]
    }
   ],
   "source": [
    "total_count_matrix = []\n",
    "for idx in tqdm(range(80)):\n",
    "    df_case = pd.read_csv(check_folder_path + '/' + litbank_file_list[idx], index_col=0)\n",
    "    df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "    df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "    df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "    df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "    df_case['inference_offsets'] = [ast.literal_eval(data) for data in df_case['inference_offsets']]\n",
    "    df_case = df_case[df_case['update_text'].notna()].reset_index(drop=True)\n",
    "    df_dh = pd.read_csv(PATH + '/NewLitBank_dh/' + litbank_file_list[idx], index_col=0)\n",
    "    df_js = pd.read_csv(PATH + '/NewLitBank_JS/' + litbank_file_list[idx], index_col=0).reset_index(drop=True)\n",
    "    df_gy = pd.read_csv(PATH + '/NewLitBank_gy/' + litbank_file_list[idx])\n",
    "    annotators = [df_dh, df_js, df_gy]\n",
    "    num_cases = len(df_dh)\n",
    "    count_matrix = np.zeros((num_cases, num_classes), dtype=int)\n",
    "    for df in annotators:\n",
    "        if len(df['cases'])==0: \n",
    "            break\n",
    "        for i, label in enumerate(df['cases']):\n",
    "            count_matrix[i, label] += 1\n",
    "    df_case['cases'] = final_labels(count_matrix)\n",
    "    df_case.to_csv('../data/NewLitBank_ECAI/' + litbank_file_list[idx])\n",
    "    total_count_matrix.append(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14f86034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0],\n",
       "       [3, 0, 0],\n",
       "       [3, 0, 0],\n",
       "       ...,\n",
       "       [1, 2, 0],\n",
       "       [3, 0, 0],\n",
       "       [1, 2, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8cd2d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count_matrix = np.vstack(total_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4cbc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = fleiss_kappa(total_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bdd914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa: 0.4630\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fleiss' Kappa: {kappa:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
