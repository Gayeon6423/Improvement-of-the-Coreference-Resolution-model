{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b4d7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e653f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    return int(filename.split('_')[-1].split('.')[0])\n",
    "\n",
    "PATH = '../data'\n",
    "LITBANK_INDEX=0\n",
    "check_folder_path = '../data/NewLitBank_v2'\n",
    "litbank_file_list = sorted(os.listdir(check_folder_path), key=extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = pd.read_csv(check_folder_path + '/' + litbank_file_list[LITBANK_INDEX], index_col=0)\n",
    "df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "df_case['inference_offsets'] = [ast.literal_eval(data) for data in df_case['inference_offsets']]\n",
    "df_case = df_case[df_case['update_text'].notna()].reset_index(drop=True)\n",
    "\n",
    "# Each Persons's Evaluation\n",
    "df_dh = pd.read_csv(PATH + '/NewLitBank_dh/' + litbank_file_list[LITBANK_INDEX], index_col=0)\n",
    "df_js = pd.read_csv(PATH + '/NewLitBank_js/' + litbank_file_list[LITBANK_INDEX], index_col=0).reset_index(drop=True)\n",
    "df_gy = pd.read_csv(PATH + '/NewLitBank_gy/' + litbank_file_list[LITBANK_INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d3c9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_labels(count_matrix):\n",
    "    argmax_labels = []\n",
    "    for row in count_matrix:\n",
    "        max_val = np.max(row)\n",
    "        max_indices = np.where(row == max_val)[0]\n",
    "\n",
    "        if len(max_indices) == 1:\n",
    "            argmax_labels.append(max_indices[0]) \n",
    "        else:\n",
    "            argmax_labels.append(1)\n",
    "    return argmax_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ff158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:01<00:00, 66.47it/s]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 3\n",
    "total_count_matrix = []\n",
    "for idx in tqdm(range(80)):\n",
    "    df_case = pd.read_csv(check_folder_path + '/' + litbank_file_list[idx], index_col=0)\n",
    "    df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "    df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "    df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "    df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "    df_case['inference_offsets'] = [ast.literal_eval(data) for data in df_case['inference_offsets']]\n",
    "    df_case = df_case[df_case['update_text'].notna()].reset_index(drop=True)\n",
    "    df_dh = pd.read_csv(PATH + '/NewLitBank_dh/' + litbank_file_list[idx], index_col=0)\n",
    "    df_js = pd.read_csv(PATH + '/NewLitBank_JS/' + litbank_file_list[idx], index_col=0).reset_index(drop=True)\n",
    "    df_gy = pd.read_csv(PATH + '/NewLitBank_gy/' + litbank_file_list[idx])\n",
    "    annotators = [df_dh, df_js, df_gy]\n",
    "    num_cases = len(df_dh)\n",
    "    count_matrix = np.zeros((num_cases, num_classes), dtype=int)\n",
    "    for df in annotators:\n",
    "        if len(df['cases'])==0: \n",
    "            break\n",
    "        for i, label in enumerate(df['cases']):\n",
    "            count_matrix[i, label] += 1\n",
    "    df_case['cases'] = final_labels(count_matrix)\n",
    "    df_case.to_csv('data/NewLitBank_IAA/' + litbank_file_list[idx])\n",
    "    total_count_matrix.append(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bdd914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa: 0.4630\n"
     ]
    }
   ],
   "source": [
    "total_count_matrix = np.vstack(total_count_matrix)\n",
    "kappa = fleiss_kappa(total_count_matrix)\n",
    "print(f\"Fleiss' Kappa: {kappa:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
