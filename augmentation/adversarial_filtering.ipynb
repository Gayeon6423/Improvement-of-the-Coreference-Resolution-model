{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brave new ADVERSIAL FILTERING for our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Current working directory: /home/gayeon39/gayeon/[연구]Coreference Resolution/coref-main/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon39/miniconda3/envs/coref_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setting\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "os.chdir(os.path.join(os.getcwd(), '..', 'model'))\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from utils_filtering import *\n",
    "from maverick import Maverick\n",
    "\n",
    "# Config\n",
    "config_path = \"../config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "open_api_key = config['openai_api']\n",
    "folder_path = \"../data/LitBank_Case/\"\n",
    "\n",
    "# Augmentation Index\n",
    "case_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sapienzanlp/maverick-mes-litbank loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gayeon39/miniconda3/envs/coref_env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/gayeon39/miniconda3/envs/coref_env/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = Maverick(hf_name_or_path = \"sapienzanlp/maverick-mes-litbank\",  device = \"cuda:0\") \n",
    "client = OpenAI(api_key=open_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "    match = re.search(r'_(\\d+)\\.csv$', filename)\n",
    "    return int(match.group(1)) if match else float('inf')\n",
    "\n",
    "csv_files = sorted(csv_files, key=extract_number)\n",
    "df_case = pd.read_csv(folder_path + csv_files[0])\n",
    "\n",
    "df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"You will be given a sentence in OntoNotes format along with a coreference cluster and its offsets. Your task is to add **only one adjective** that aligns with the given coreference term. The adjective must be placed **immediately before** the term within the sentence.\n",
    "\n",
    "### Guidelines:\n",
    "1. Identify the words in the sentence that correspond to each offset.\n",
    "2. Updated Coreference Offsets should be calculated step by step.\n",
    "3. For each remaining term (starting from the second), add **only one adjective** **immediately before** the term if it adds meaningful context.\n",
    "4. **Never add articles ('the', 'a')**, only one adjective.\n",
    "5. Ensure the adjective does not change the sentence's original meaning.\n",
    "6. **Avoid repeating the same word multiple times in sequence** (e.g., avoid adding 'large' twice in a row like 'large large').\n",
    "7. Use adjectives that are contextually relevant and meaningful. Avoid using too general adjectives like 'good', 'bad', 'nice', or nonsensical combinations.\n",
    "8. Adjectives should enrich the meaning or add useful information without making the description redundant or awkward.\n",
    "9. **If no suitable adjective can be added without disrupting the meaning or creating redundancy, do not add an adjective at all.** The coreference term should remain unchanged in such cases.\n",
    "10. **NEVER VIOLATE THE OUTPUT TEMPLATE**\n",
    "\n",
    "### Input:\n",
    "- Sentence: {ontonotes_sentence}\n",
    "- Coreference Offsets: {offsets} \n",
    "- Coreference Words: {words} \n",
    "\n",
    "### Output Format:\n",
    "1. Updated Coreference Words : The modified OntoNotes format sentence with adjectives added.\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "- Sentence: ['Barack', 'Obama', 'is', 'traveling', 'to', 'Rome', '.', 'The', 'city', 'is', 'sunny', 'and', 'the', 'president', 'plans', 'to', 'visit', 'its', 'most', 'important', 'attractions']\n",
    "- Coreference Offsets: [[5, 5], [7, 8], [17, 17]]\n",
    "- Coreference Words: [['Rome'], ['The', 'city'], ['its']]\n",
    "\n",
    "**Correct Output**:\n",
    "1. Updated Coreference Words : [['Rome'], ['The', 'picturesque', 'city'], ['its']]\n",
    "\n",
    "**Explanation**: \n",
    "- 'picturesque' was added to 'city' to enrich the description without altering the intended meaning.\n",
    "- No adjective was added to 'Rome' or 'its' as it was unnecessary.\n",
    "\n",
    "Now, process the following input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_prompt_text = \"\"\"This prompt is that the output form of the previous request was not correct, please do it again according to the request below.\n",
    "You will be given a sentence in OntoNotes format along with a coreference cluster and its offsets. Your task is to add **only one adjective** that aligns with the given coreference term. The adjective must be placed **immediately before** the term within the sentence.\n",
    "\n",
    "### Guidelines:\n",
    "1. Identify the words in the sentence that correspond to each offset.\n",
    "2. Updated Coreference Offsets should be calculated step by step.\n",
    "3. For each remaining term (starting from the second), add **only one adjective** **immediately before** the term if it adds meaningful context.\n",
    "4. **Never add articles ('the', 'a')**, only one adjective.\n",
    "5. Ensure the adjective does not change the sentence's original meaning.\n",
    "6. **Avoid repeating the same word multiple times in sequence** (e.g., avoid adding 'large' twice in a row like 'large large').\n",
    "7. Use adjectives that are contextually relevant and meaningful. Avoid using too general adjectives like 'good', 'bad', 'nice', or nonsensical combinations.\n",
    "8. Adjectives should enrich the meaning or add useful information without making the description redundant or awkward.\n",
    "9. **If no suitable adjective can be added without disrupting the meaning or creating redundancy, do not add an adjective at all.** The coreference term should remain unchanged in such cases.\n",
    "10. **NEVER VIOLATE THE OUTPUT TEMPLATE**\n",
    "\n",
    "### Input:\n",
    "- Sentence: {ontonotes_sentence}\n",
    "- Coreference Offsets: {offsets} \n",
    "- Coreference Words: {words} \n",
    "\n",
    "### Output Format:\n",
    "1. Updated Coreference Words : The modified OntoNotes format sentence with adjectives added.\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "- Sentence: ['Barack', 'Obama', 'is', 'traveling', 'to', 'Rome', '.', 'The', 'city', 'is', 'sunny', 'and', 'the', 'president', 'plans', 'to', 'visit', 'its', 'most', 'important', 'attractions']\n",
    "- Coreference Offsets: [[5, 5], [7, 8], [17, 17]]\n",
    "- Coreference Words: [['Rome'], ['The', 'city'], ['its']]\n",
    "\n",
    "**Correct Output**:\n",
    "1. Updated Coreference Words : [['Rome'], ['The', 'picturesque', 'city'], ['its']]\n",
    "\n",
    "**Explanation**: \n",
    "- 'picturesque' was added to 'city' to enrich the description without altering the intended meaning.\n",
    "- No adjective was added to 'Rome' or 'its' as it was unnecessary.\n",
    "\n",
    "Now, process the following input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_prompt_text = '''You will be given a sentence in modified OntoNotes format along with coreference information. Your task is to replace any easily identifiable adjectives (such as `beautiful`) in the **Updated Coreference Words** with more challenging and sophisticated words that make the target reference less obvious. Follow these rules:\n",
    "\n",
    "### Guidelines:\n",
    "1. Identify the words in the sentence that correspond to each offset.\n",
    "2. Updated Coreference Offsets should be calculated step by step.\n",
    "3. For each remaining term (starting from the second), add **only one adjective** **immediately before** the term if it adds meaningful context.\n",
    "4. **Never add articles ('the', 'a')**, only one adjective.\n",
    "5. Ensure the adjective does not change the sentence's original meaning.\n",
    "6. **Avoid repeating the same word multiple times in sequence** (e.g., avoid adding 'large' twice in a row like 'large large').\n",
    "7. Use adjectives that are contextually relevant and meaningful. Avoid using too general adjectives like 'good', 'bad', 'nice', or nonsensical combinations.\n",
    "8. Adjectives should enrich the meaning or add useful information without making the description redundant or awkward.\n",
    "9. **If no suitable adjective can be added without disrupting the meaning or creating redundancy, do not add an adjective at all.** The coreference term should remain unchanged in such cases.\n",
    "10. **NEVER VIOLATE THE OUTPUT TEMPLATE**\n",
    "\n",
    "### Input:\n",
    "- Modified Sentence: {modified_ontonotes_sentence}\n",
    "- Original Coreference Words: {original_coreference_words}\n",
    "- Updated Coreference Words: {updated_coreference_words}\n",
    "- Updated Coreference Offsets: {updated_coreference_offsets}\n",
    "\n",
    "### Output Format:\n",
    "1. Further Updated Coreference Words: List of coreference terms showing any adjective changes made.\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "- Modified Sentence: ['Barack', 'Obama', 'is', 'traveling', 'to', 'Rome', '.', 'The', 'beautiful', 'city', 'is', 'sunny', 'and', 'the', 'president', 'plans', 'to', 'visit', 'its', 'most', 'important', 'attractions']\n",
    "- Original Coreference Words: [['Rome'], ['The', 'city'], ['its']]\n",
    "- Updated Coreference Words: [['Rome'], ['The', 'beautiful', 'city'], ['its']]\n",
    "- Updated Coreference Offsets: [[5, 5], [7, 9], [18, 18]]\n",
    "\n",
    "**Correct Output**:\n",
    "1. Further Updated Coreference Words : [['Rome'], ['The', 'ornate', 'city'], ['its']]\n",
    "\n",
    "### Explain the Output Example\n",
    "1. Updated Corefernece Words : 'beautiful' is changed as 'ornate' which is an appropriate adjective for the meaning of a sentence \n",
    "\n",
    "Now, process the following input.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_next_prompt_text = \"\"\"This prompt is that the output form of the previous request was not correct, please do it again according to the request below.\n",
    "You will be given a sentence in modified OntoNotes format along with coreference information. Your task is to replace any easily identifiable adjectives (such as `beautiful`) in the **Updated Coreference Words** with more challenging and sophisticated words that make the target reference less obvious. Follow these rules:\n",
    "\n",
    "### Guidelines:\n",
    "1. Identify the words in the sentence that correspond to each offset.\n",
    "2. Updated Coreference Offsets should be calculated step by step.\n",
    "3. For each remaining term (starting from the second), add **only one adjective** **immediately before** the term if it adds meaningful context.\n",
    "4. **Never add articles ('the', 'a')**, only one adjective.\n",
    "5. Ensure the adjective does not change the sentence's original meaning.\n",
    "6. **Avoid repeating the same word multiple times in sequence** (e.g., avoid adding 'large' twice in a row like 'large large').\n",
    "7. Use adjectives that are contextually relevant and meaningful. Avoid using too general adjectives like 'good', 'bad', 'nice', or nonsensical combinations.\n",
    "8. Adjectives should enrich the meaning or add useful information without making the description redundant or awkward.\n",
    "9. **If no suitable adjective can be added without disrupting the meaning or creating redundancy, do not add an adjective at all.** The coreference term should remain unchanged in such cases.\n",
    "10. **NEVER VIOLATE THE OUTPUT TEMPLATE**\n",
    "\n",
    "### Input:\n",
    "- Modified Sentence: {modified_ontonotes_sentence}\n",
    "- Original Coreference Words: {original_coreference_words}\n",
    "- Updated Coreference Words: {updated_coreference_words}\n",
    "- Updated Coreference Offsets: {updated_coreference_offsets}\n",
    "\n",
    "### Output Format:\n",
    "1. Further Updated Coreference Words: List of coreference terms showing any adjective changes made.\n",
    "\n",
    "### Example:\n",
    "Input:\n",
    "- Modified Sentence: ['Barack', 'Obama', 'is', 'traveling', 'to', 'Rome', '.', 'The', 'beautiful', 'city', 'is', 'sunny', 'and', 'the', 'president', 'plans', 'to', 'visit', 'its', 'most', 'important', 'attractions']\n",
    "- Original Coreference Words: [['Rome'], ['The', 'city'], ['its']]\n",
    "- Updated Coreference Words: [['Rome'], ['The', 'beautiful', 'city'], ['its']]\n",
    "- Updated Coreference Offsets: [[5, 5], [7, 9], [18, 18]]\n",
    "\n",
    "**Correct Output**:\n",
    "1. Further Updated Coreference Words : [['Rome'], ['The', 'ornate', 'city'], ['its']]\n",
    "\n",
    "### Explain the Output Example\n",
    "1. Updated Corefernece Words : 'beautiful' is changed as 'ornate' which is an appropriate adjective for the meaning of a sentence \n",
    "\n",
    "Now, process the following input.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12089 [10:31:57<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "def model_inference(sentence):\n",
    "    result = model.predict(sentence)\n",
    "    clusters_token_offsets_list = clusters_token_offsets_to_list(result['clusters_token_offsets'])\n",
    "    return clusters_token_offsets_list\n",
    "\n",
    "progress_bar = tqdm(total=(len(csv_files) - case_idx))\n",
    "while case_idx<len(csv_files):\n",
    "    step = 0\n",
    "    coref_case = csv_files[case_idx]\n",
    "    df_case = pd.read_csv(folder_path + coref_case)\n",
    "    df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "    df_case['extracted_sentence'] = df_case['extracted_sentence'].apply(ontonote_to_list)\n",
    "    df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "    df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "    df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "    \n",
    "    New_LitBank_df = pd.DataFrame()\n",
    "    \n",
    "    while True:\n",
    "        #Terminate\n",
    "        step += 1\n",
    "        if df_case.empty:\n",
    "            # Maverick doesn't predict all case at first -> we need to add each col to fit other form\n",
    "            for col in ['update_sentence', 'update_coref', 'update_text']:\n",
    "                if col not in New_LitBank_df.columns:\n",
    "                    New_LitBank_df[col] = np.nan\n",
    "            break\n",
    "        \n",
    "        #Prevent too much augmentation. Actually, if the step is bigger than 10, it must be some problem in the extracting update words.\n",
    "        if step>100:\n",
    "            New_LitBank_df = pd.concat([New_LitBank_df, df_case]).reset_index(drop=True)\n",
    "            break\n",
    "        \n",
    "        #First step\n",
    "        if step == 1:\n",
    "            #model inference\n",
    "            df_case['inference_offsets'] = df_case['extracted_sentence'].apply(model_inference)\n",
    "            df_case['labels'] = [1 if data.adjusted_offsets in data.inference_offsets else 0 for data in df_case.itertuples()]\n",
    "            \n",
    "            #New LitBank\n",
    "            New_LitBank_df = pd.concat([New_LitBank_df, df_case[df_case['labels']==0]]).reset_index(drop=True)\n",
    "            df_case = df_case[df_case['labels']==1].reset_index(drop=True)\n",
    "            \n",
    "            update_text_list = []\n",
    "            prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "\n",
    "            for data in df_case.itertuples():\n",
    "                ontonotes_sentence = data.extracted_sentence\n",
    "                offsets = data.adjusted_offsets\n",
    "                words = data.text\n",
    "                while True:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=[{\"role\": \"user\",\n",
    "                                \"content\": prompt.format(\n",
    "                                            ontonotes_sentence=ontonotes_sentence,\n",
    "                                            offsets=offsets,\n",
    "                                            words=words\n",
    "                                        )}])\n",
    "                    output_text = response.choices[0].message.content\n",
    "                    updated_coreference_words_match = re.search(r\"Updated Coreference Words\\s*:\\s*(\\[\\[.*?\\]\\])\", output_text, re.DOTALL)\n",
    "\n",
    "                    if updated_coreference_words_match:\n",
    "                        updated_coreference_words = updated_coreference_words_match.group(1) if updated_coreference_words_match else None\n",
    "                        updated_coreference_words = ast.literal_eval(updated_coreference_words) if updated_coreference_words else None\n",
    "                    else:\n",
    "                        prompt = ChatPromptTemplate.from_template(request_prompt_text)\n",
    "                        continue\n",
    "                    \n",
    "                    if updated_coreference_words==data.text or len(updated_coreference_words)!=len(offsets):\n",
    "                        prompt = ChatPromptTemplate.from_template(request_prompt_text)\n",
    "                    else:\n",
    "                        prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "                        break\n",
    "                            \n",
    "                update_text_list.append(updated_coreference_words)\n",
    "            \n",
    "            df_case['update_text'] = update_text_list\n",
    "            df_case['update_sentence'] = df_case.apply(lambda x: replace_words_by_dynamic_indices(x['extracted_sentence'], x['adjusted_offsets'], x['update_text']), axis=1) if df_case.empty==False else []\n",
    "            df_case['update_coref'] = df_case.apply(lambda x: offset_modify(x['adjusted_offsets'], x['update_text']), axis=1) if df_case.empty==False else []\n",
    "            \n",
    "        #After first\n",
    "        else:\n",
    "            #model inference\n",
    "            df_case['inference_offsets'] = df_case['update_sentence'].apply(model_inference)\n",
    "            df_case['labels'] = [1 if data.update_coref in data.inference_offsets else 0 for data in df_case.itertuples()]\n",
    "            #New LitBank\n",
    "            New_LitBank_df = pd.concat([New_LitBank_df, df_case[df_case['labels']==0]]).reset_index(drop=True)\n",
    "            df_case = df_case[df_case['labels']==1].reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            update_text_list = []\n",
    "            prompt = ChatPromptTemplate.from_template(next_prompt_text)\n",
    "\n",
    "            for data in df_case.itertuples():\n",
    "                modified_ontonotes_sentence = data.update_sentence\n",
    "                original_coreference_words = data.adjusted_offsets\n",
    "                updated_coreference_words = data.update_text\n",
    "                updated_coreference_offsets = data.update_coref\n",
    "                while True:\n",
    "                    response = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        messages=[{\"role\": \"user\",\n",
    "                                \"content\": prompt.format(\n",
    "                                        modified_ontonotes_sentence=modified_ontonotes_sentence,\n",
    "                                        original_coreference_words=original_coreference_words,\n",
    "                                        updated_coreference_words=updated_coreference_words,\n",
    "                                        updated_coreference_offsets=updated_coreference_offsets\n",
    "                                    )}])\n",
    "                    output_text = response.choices[0].message.content\n",
    "                    updated_coreference_words_match = re.search(r\"Further Updated Coreference Words\\s*:\\s*(\\[\\[.*?\\]\\])\", output_text, re.DOTALL)\n",
    "       \n",
    "\n",
    "                    if updated_coreference_words_match:\n",
    "                        next_updated_coreference_words = updated_coreference_words_match.group(1) if updated_coreference_words_match else None\n",
    "                        next_updated_coreference_words = ast.literal_eval(next_updated_coreference_words) if next_updated_coreference_words else None\n",
    "                    else:\n",
    "                        prompt = ChatPromptTemplate.from_template(request_next_prompt_text)\n",
    "                        continue\n",
    "                    \n",
    "                    if next_updated_coreference_words==data.text or len(next_updated_coreference_words)!=len(updated_coreference_offsets):\n",
    "                        prompt = ChatPromptTemplate.from_template(next_prompt_text)\n",
    "                    else:\n",
    "                        prompt = ChatPromptTemplate.from_template(request_next_prompt_text)\n",
    "                        break\n",
    "                update_text_list.append(next_updated_coreference_words)\n",
    "                \n",
    "            df_case['update_text'] = update_text_list\n",
    "            df_case['update_sentence'] = df_case.apply(lambda x: replace_words_by_dynamic_indices(x['update_sentence'], x['update_coref'], x['update_text']), axis=1) if df_case.empty==False else []\n",
    "            df_case['update_coref'] = df_case.apply(lambda x: offset_modify(x['update_coref'], x['update_text']), axis=1) if df_case.empty==False else []\n",
    "\n",
    "        df_case = df_case[df_case['labels']==1].reset_index(drop=True)\n",
    "    New_LitBank_df.to_csv(f'../maverick_augmentation/datasets/Experiment/New_LitBank/New_litbank_case_{coref_case}')\n",
    "    progress_bar.update(1)\n",
    "    case_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GENLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
