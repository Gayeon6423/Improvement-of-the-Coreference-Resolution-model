{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Checking List]\n",
    "- 원본 공동참조 단어(text)과 증강한 공동참조(update_text)을 비교해서 제대로 증강했는지 확인\n",
    "- 원본 문장(extracted_sentence)과 증강한 문장(updated_sentence)을 비교해서 제대로 증강했는지 확인\n",
    "- 증강한 단어(update_text)가 증강한 문장(update_sentence)에 포함되어 있는지 확인\n",
    "- 증강한 단어(update_text)가 증강한 문장 인덱스(update_coref)와 일치하는지 확인\n",
    "\n",
    "[Labeling Criterion]\n",
    "- Best(0) : 문맥에 맞게 형용사 잘 증강한 경우\n",
    "- Worst(1) : 의미는 맞지만 풀어서 문맥 증강한 경우, 기존 단어 사라짐\n",
    "- Weird(2) : offset안맞음, 대명사 앞에 형용사 증강, James Handsome Bond 처럼 명사 중간에 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def extract_number(filename):\n",
    "    return int(filename.split('_')[-1].split('.')[0])\n",
    "\n",
    "check_folder_path = '../data/NewLitBank_v2/'\n",
    "save_folder_path = '../data/NewLitBank_Final_가연/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 개수 :  22\n",
      "결측치 개수 :  15\n"
     ]
    }
   ],
   "source": [
    "RAW_CASE_INDEX = 0\n",
    "\n",
    "litbank_file_list = sorted(os.listdir(check_folder_path), key=extract_number)\n",
    "df_case = pd.read_csv(check_folder_path + '/' + litbank_file_list[RAW_CASE_INDEX])\n",
    "df_case.drop(columns='Unnamed: 0', inplace=True)\n",
    "df_case['cases'] = ''\n",
    "print('전체 개수 : ', len(df_case))\n",
    "print('결측치 개수 : ', df_case.isnull().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref</th>\n",
       "      <th>extracted_sentence</th>\n",
       "      <th>adjusted_offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>inference_offsets</th>\n",
       "      <th>labels</th>\n",
       "      <th>update_text</th>\n",
       "      <th>update_sentence</th>\n",
       "      <th>update_coref</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[450, 454], [18, 19], [22, 23], [247, 250], [...</td>\n",
       "      <td>[To, accommodate, the, regiments, of, miners, ...</td>\n",
       "      <td>[[35, 39], [64, 65], [68, 69], [90, 93], [116,...</td>\n",
       "      <td>[[the, site, of, Hell, Row], [Hell, Row], [Hel...</td>\n",
       "      <td>[[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[the, site, of, Hell, Row], [notorious, Hell,...</td>\n",
       "      <td>[To, accommodate, the, regiments, of, miners, ...</td>\n",
       "      <td>[[35, 39], [64, 66], [69, 71], [92, 95], [118,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[43, 53], [605, 606], [144, 145]]</td>\n",
       "      <td>[There, lived, the, colliers, who, worked, in,...</td>\n",
       "      <td>[[2, 12], [30, 31], [39, 40]]</td>\n",
       "      <td>[[the, colliers, who, worked, in, the, little,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[the, colliers, who, worked, in, the, little,...</td>\n",
       "      <td>[There, lived, the, colliers, who, worked, in,...</td>\n",
       "      <td>[[2, 12], [30, 32], [40, 42]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[209, 209], [393, 393]]</td>\n",
       "      <td>[The, coal, and, iron, field, of, Nottinghamsh...</td>\n",
       "      <td>[[8, 8], [92, 92]]</td>\n",
       "      <td>[[Derbyshire], [Derbyshire]]</td>\n",
       "      <td>[[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Derbyshire], [picturesque, Derbyshire]]</td>\n",
       "      <td>[The, coal, and, iron, field, of, Nottinghamsh...</td>\n",
       "      <td>[[8, 8], [92, 93]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[345, 346], [234, 235]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[32, 33], [116, 117]]</td>\n",
       "      <td>[[Spinney, Park], [Spinney, Park]]</td>\n",
       "      <td>[[[39, 39], [48, 48]], [[56, 58], [62, 62]]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Spinney, picturesque, Park], [Spinney, pictu...</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[32, 34], [117, 119]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[382, 382], [296, 296]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[69, 69], [125, 125]]</td>\n",
       "      <td>[[Selby], [Selby]]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Selby], [the, nearby, Selby]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[69, 69], [125, 127]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[314, 314], [298, 298]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[1, 1], [127, 127]]</td>\n",
       "      <td>[[Nuttall], [Nuttall]]</td>\n",
       "      <td>[[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Nuttall], [Nuttall, new]]</td>\n",
       "      <td>[From, Nuttall, ,, high, up, on, the, sandston...</td>\n",
       "      <td>[[1, 1], [127, 128]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[1162, 1162], [1183, 1183]]</td>\n",
       "      <td>[“, They, 'll, be, beginnin, ', ,, ”, the, boy...</td>\n",
       "      <td>[[1, 1], [22, 22]]</td>\n",
       "      <td>[[They], [they]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[They], [the, mother]]</td>\n",
       "      <td>[“, They, 'll, be, beginnin, ', ,, ”, the, boy...</td>\n",
       "      <td>[[1, 1], [22, 23]]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                coref  \\\n",
       "15  [[450, 454], [18, 19], [22, 23], [247, 250], [...   \n",
       "16                 [[43, 53], [605, 606], [144, 145]]   \n",
       "17                           [[209, 209], [393, 393]]   \n",
       "18                           [[345, 346], [234, 235]]   \n",
       "19                           [[382, 382], [296, 296]]   \n",
       "20                           [[314, 314], [298, 298]]   \n",
       "21                       [[1162, 1162], [1183, 1183]]   \n",
       "\n",
       "                                   extracted_sentence  \\\n",
       "15  [To, accommodate, the, regiments, of, miners, ...   \n",
       "16  [There, lived, the, colliers, who, worked, in,...   \n",
       "17  [The, coal, and, iron, field, of, Nottinghamsh...   \n",
       "18  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "19  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "20  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "21  [“, They, 'll, be, beginnin, ', ,, ”, the, boy...   \n",
       "\n",
       "                                     adjusted_offsets  \\\n",
       "15  [[35, 39], [64, 65], [68, 69], [90, 93], [116,...   \n",
       "16                      [[2, 12], [30, 31], [39, 40]]   \n",
       "17                                 [[8, 8], [92, 92]]   \n",
       "18                             [[32, 33], [116, 117]]   \n",
       "19                             [[69, 69], [125, 125]]   \n",
       "20                               [[1, 1], [127, 127]]   \n",
       "21                                 [[1, 1], [22, 22]]   \n",
       "\n",
       "                                                 text  \\\n",
       "15  [[the, site, of, Hell, Row], [Hell, Row], [Hel...   \n",
       "16  [[the, colliers, who, worked, in, the, little,...   \n",
       "17                       [[Derbyshire], [Derbyshire]]   \n",
       "18                 [[Spinney, Park], [Spinney, Park]]   \n",
       "19                                 [[Selby], [Selby]]   \n",
       "20                             [[Nuttall], [Nuttall]]   \n",
       "21                                   [[They], [they]]   \n",
       "\n",
       "                                    inference_offsets  labels  \\\n",
       "15  [[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...       0   \n",
       "16                                                 []       0   \n",
       "17  [[[50, 50], [59, 59]], [[67, 69], [73, 73]], [...       0   \n",
       "18       [[[39, 39], [48, 48]], [[56, 58], [62, 62]]]       0   \n",
       "19  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "20  [[[38, 38], [47, 47]], [[55, 57], [61, 61]], [...       0   \n",
       "21                                                 []       0   \n",
       "\n",
       "                                          update_text  \\\n",
       "15  [[the, site, of, Hell, Row], [notorious, Hell,...   \n",
       "16  [[the, colliers, who, worked, in, the, little,...   \n",
       "17          [[Derbyshire], [picturesque, Derbyshire]]   \n",
       "18  [[Spinney, picturesque, Park], [Spinney, pictu...   \n",
       "19                    [[Selby], [the, nearby, Selby]]   \n",
       "20                        [[Nuttall], [Nuttall, new]]   \n",
       "21                            [[They], [the, mother]]   \n",
       "\n",
       "                                      update_sentence  \\\n",
       "15  [To, accommodate, the, regiments, of, miners, ...   \n",
       "16  [There, lived, the, colliers, who, worked, in,...   \n",
       "17  [The, coal, and, iron, field, of, Nottinghamsh...   \n",
       "18  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "19  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "20  [From, Nuttall, ,, high, up, on, the, sandston...   \n",
       "21  [“, They, 'll, be, beginnin, ', ,, ”, the, boy...   \n",
       "\n",
       "                                         update_coref cases  \n",
       "15  [[35, 39], [64, 66], [69, 71], [92, 95], [118,...        \n",
       "16                      [[2, 12], [30, 32], [40, 42]]        \n",
       "17                                 [[8, 8], [92, 93]]        \n",
       "18                             [[32, 34], [117, 119]]        \n",
       "19                             [[69, 69], [125, 127]]        \n",
       "20                               [[1, 1], [127, 128]]        \n",
       "21                                 [[1, 1], [22, 23]]        "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case = df_case.dropna() # nan 값 제거\n",
    "df_case['coref'] = [ast.literal_eval(data) for data in df_case['coref']]\n",
    "df_case['extracted_sentence'] = [ast.literal_eval(data) for data in df_case['extracted_sentence']]\n",
    "df_case['adjusted_offsets'] = [ast.literal_eval(data) for data in df_case['adjusted_offsets']]\n",
    "df_case['text'] = [ast.literal_eval(data) for data in df_case['text']]\n",
    "df_case['inference_offsets'] = [ast.literal_eval(data) for data in df_case['inference_offsets']]\n",
    "df_case['update_text'] = [ast.literal_eval(data) for data in df_case['update_text']]\n",
    "df_case['update_sentence'] = [ast.literal_eval(data) for data in df_case['update_sentence']]\n",
    "df_case['update_coref'] = [ast.literal_eval(data) for data in df_case['update_coref']]\n",
    "df_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_INDEX = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문장 길이 :  130\n",
      "증강된 문장 길이 :  132\n",
      "원본 공동참조 단어 :  [['the', 'site', 'of', 'Hell', 'Row'], ['Hell', 'Row'], ['Hell', 'Row'], ['the', 'notorious', 'Hell', 'Row'], ['There']]\n",
      "원본 공동참조 인덱스 :  [[35, 39], [64, 65], [68, 69], [90, 93], [116, 116]]\n",
      "증강된 공동참조 단어 :  [['the', 'site', 'of', 'Hell', 'Row'], ['notorious', 'Hell', 'Row'], ['notorious', 'Hell', 'Row'], ['the', 'notorious', 'Hell', 'Row'], ['There']]\n",
      "증강된 공동참조 인덱스 :  [[35, 39], [64, 66], [69, 71], [92, 95], [118, 118]]\n",
      "원본 공동참조 문장 :  ['To', 'accommodate', 'the', 'regiments', 'of', 'miners', ',', 'Carston', ',', 'Waite', 'and', 'Co.', 'built', 'the', 'Squares', ',', 'great', 'quadrangles', 'of', 'dwellings', 'on', 'the', 'hillside', 'of', 'Bestwood', ',', 'and', 'then', ',', 'in', 'the', 'brook', 'valley', ',', 'on', 'the', 'site', 'of', 'Hell', 'Row', ',', 'they', 'erected', 'the', 'Bottoms', '.', 'PART', 'ONE', 'CHAPTER', 'I', 'THE', 'EARLY', 'MARRIED', 'LIFE', 'OF', 'THE', 'MORELS', '“', 'THE', 'BOTTOMS', '”', 'succeeded', 'to', '“', 'Hell', 'Row', '”', '.', 'Hell', 'Row', 'was', 'a', 'block', 'of', 'thatched', ',', 'bulging', 'cottages', 'that', 'stood', 'by', 'the', 'brookside', 'on', 'Greenhill', 'Lane', '.', 'About', 'this', 'time', 'the', 'notorious', 'Hell', 'Row', ',', 'which', 'through', 'growing', 'old', 'had', 'acquired', 'an', 'evil', 'reputation', ',', 'was', 'burned', 'down', ',', 'and', 'much', 'dirt', 'was', 'cleansed', 'away', '.', 'There', 'lived', 'the', 'colliers', 'who', 'worked', 'in', 'the', 'little', 'gin-pits', 'two', 'fields', 'away', '.']\n",
      "증강된 공동참조 문장 :  ['To', 'accommodate', 'the', 'regiments', 'of', 'miners', ',', 'Carston', ',', 'Waite', 'and', 'Co.', 'built', 'the', 'Squares', ',', 'great', 'quadrangles', 'of', 'dwellings', 'on', 'the', 'hillside', 'of', 'Bestwood', ',', 'and', 'then', ',', 'in', 'the', 'brook', 'valley', ',', 'on', 'the', 'site', 'of', 'Hell', 'Row', ',', 'they', 'erected', 'the', 'Bottoms', '.', 'PART', 'ONE', 'CHAPTER', 'I', 'THE', 'EARLY', 'MARRIED', 'LIFE', 'OF', 'THE', 'MORELS', '“', 'THE', 'BOTTOMS', '”', 'succeeded', 'to', '“', 'notorious', 'Hell', 'Row', '”', '.', 'notorious', 'Hell', 'Row', 'was', 'a', 'block', 'of', 'thatched', ',', 'bulging', 'cottages', 'that', 'stood', 'by', 'the', 'brookside', 'on', 'Greenhill', 'Lane', '.', 'About', 'this', 'time', 'the', 'notorious', 'Hell', 'Row', ',', 'which', 'through', 'growing', 'old', 'had', 'acquired', 'an', 'evil', 'reputation', ',', 'was', 'burned', 'down', ',', 'and', 'much', 'dirt', 'was', 'cleansed', 'away', '.', 'There', 'lived', 'the', 'colliers', 'who', 'worked', 'in', 'the', 'little', 'gin-pits', 'two', 'fields', 'away', '.']\n"
     ]
    }
   ],
   "source": [
    "print('원본 문장 길이 : ', len(df_case['extracted_sentence'][CHECK_INDEX]))\n",
    "print('증강된 문장 길이 : ',len(df_case['update_sentence'][CHECK_INDEX]))\n",
    "print('원본 공동참조 단어 : ', df_case['text'][CHECK_INDEX])\n",
    "print('원본 공동참조 인덱스 : ', df_case['adjusted_offsets'][CHECK_INDEX])\n",
    "print('증강된 공동참조 단어 : ',df_case['update_text'][CHECK_INDEX])\n",
    "print('증강된 공동참조 인덱스 : ',df_case['update_coref'][CHECK_INDEX])\n",
    "print('원본 공동참조 문장 : ', df_case['extracted_sentence'][CHECK_INDEX])\n",
    "print('증강된 공동참조 문장 : ',df_case['update_sentence'][CHECK_INDEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 개수 :  6\n",
      "Worst 개수 :  0\n",
      "Weird 개수 :  1\n"
     ]
    }
   ],
   "source": [
    "# best=0, worst=1, weird=2\n",
    "df_case.iloc[0,9] = 2\n",
    "df_case.iloc[1,9] = 0\n",
    "df_case.iloc[2,9] = 0\n",
    "df_case.iloc[3,9] = 0\n",
    "df_case.iloc[4,9] = 0\n",
    "df_case.iloc[5,9] = 0\n",
    "df_case.iloc[6,9] = 0\n",
    "# df_case.iloc[7,9] = 2\n",
    "# df_case.iloc[8,9] = 2\n",
    "# df_case.iloc[9,9] = 0\n",
    "# df_case.iloc[10,9] = 2\n",
    "# df_case.iloc[11,9] = 0\n",
    "# df_case.iloc[12,9] = 1\n",
    "# df_case.iloc[13,9] = 1\n",
    "# df_case.iloc[14,9] = 1\n",
    "# df_case.iloc[15,9] = 2\n",
    "# df_case.iloc[16,9] = 2\n",
    "# df_case.iloc[17,9] = 0\n",
    "# df_case.iloc[18,9] = 0\n",
    "# df_case.iloc[19,9] = 0\n",
    "# df_case.iloc[20,9] = 2\n",
    "\n",
    "print('Best 개수 : ', len(df_case[df_case['cases']==0]))\n",
    "print('Worst 개수 : ', len(df_case[df_case['cases']==1]))\n",
    "print('Weird 개수 : ', len(df_case[df_case['cases']==2]))\n",
    "\n",
    "df_case.to_csv(save_folder_path + f'New_litbank_case_{RAW_CASE_INDEX}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coref</th>\n",
       "      <th>extracted_sentence</th>\n",
       "      <th>adjusted_offsets</th>\n",
       "      <th>text</th>\n",
       "      <th>inference_offsets</th>\n",
       "      <th>labels</th>\n",
       "      <th>update_text</th>\n",
       "      <th>update_sentence</th>\n",
       "      <th>update_coref</th>\n",
       "      <th>cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[450, 454], [18, 19], [22, 23], [247, 250], [...</td>\n",
       "      <td>[To, accommodate, the, regiments, of, miners, ...</td>\n",
       "      <td>[[35, 39], [64, 65], [68, 69], [90, 93], [116,...</td>\n",
       "      <td>[[the, site, of, Hell, Row], [Hell, Row], [Hel...</td>\n",
       "      <td>[[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[the, site, of, Hell, Row], [notorious, Hell,...</td>\n",
       "      <td>[To, accommodate, the, regiments, of, miners, ...</td>\n",
       "      <td>[[35, 39], [64, 66], [69, 71], [92, 95], [118,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                coref  \\\n",
       "15  [[450, 454], [18, 19], [22, 23], [247, 250], [...   \n",
       "\n",
       "                                   extracted_sentence  \\\n",
       "15  [To, accommodate, the, regiments, of, miners, ...   \n",
       "\n",
       "                                     adjusted_offsets  \\\n",
       "15  [[35, 39], [64, 65], [68, 69], [90, 93], [116,...   \n",
       "\n",
       "                                                 text  \\\n",
       "15  [[the, site, of, Hell, Row], [Hell, Row], [Hel...   \n",
       "\n",
       "                                    inference_offsets  labels  \\\n",
       "15  [[[7, 11], [41, 41]], [[43, 44], [58, 59]], [[...       0   \n",
       "\n",
       "                                          update_text  \\\n",
       "15  [[the, site, of, Hell, Row], [notorious, Hell,...   \n",
       "\n",
       "                                      update_sentence  \\\n",
       "15  [To, accommodate, the, regiments, of, miners, ...   \n",
       "\n",
       "                                         update_coref cases  \n",
       "15  [[35, 39], [64, 66], [69, 71], [92, 95], [118,...     2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
